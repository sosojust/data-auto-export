# ä½¿ç”¨ç¤ºä¾‹

æœ¬æ–‡æ¡£æä¾›äº†æ•°æ®å¯¼å‡ºç³»ç»Ÿçš„è¯¦ç»†ä½¿ç”¨ç¤ºä¾‹ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹æ–°æ¶æ„ã€‚

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…å’Œé…ç½®

```bash
# 1. è¿è¡Œå®‰è£…è„šæœ¬
./install.sh

# 2. ç¼–è¾‘é…ç½®æ–‡ä»¶
vim config.yaml

# 3. ä¸€é”®å¯åŠ¨æ‰€æœ‰æœåŠ¡
./start_all.sh

# æˆ–åˆ†åˆ«å¯åŠ¨å„ä¸ªæœåŠ¡
./start_api.sh      # APIæœåŠ¡å™¨ (ç«¯å£5001)
./start_cli.sh      # CLIè°ƒåº¦å™¨
./start_frontend.sh # å‰ç«¯æœåŠ¡å™¨ (ç«¯å£3000)
```

### 2. åŸºæœ¬é…ç½®ç¤ºä¾‹

```yaml
# config.yaml
system_database:
  type: sqlite
  sqlite_path: "./data/system.db"

data_sources:
  # MySQLæ•°æ®æº
  mysql_prod:
    type: mysql
    host: "192.168.1.100"
    port: 3306
    database: "production"
    username: "readonly_user"
    password: "your_password"
    charset: "utf8mb4"
    description: "ç”Ÿäº§ç¯å¢ƒMySQLæ•°æ®åº“"
  
  # ADBæ•°æ®æº
  adb_warehouse:
    type: adb
    host: "adb-cluster.aliyuncs.com"
    port: 3306
    database: "warehouse"
    username: "analytics_user"
    password: "your_password"
    charset: "utf8mb4"
    description: "æ•°æ®ä»“åº“ADB"

# é’‰é’‰é…ç½®
dingtalk:
  webhook_url: "https://oapi.dingtalk.com/robot/send?access_token=YOUR_TOKEN"
  secret: "YOUR_SECRET"

# é‚®ä»¶é…ç½®
email:
  smtp_server: "smtp.gmail.com"
  smtp_port: 587
  username: "your_email@gmail.com"
  password: "your_app_password"
  from_name: "æ•°æ®å¯¼å‡ºç³»ç»Ÿ"
```

## æ–°æ¶æ„æœåŠ¡ç®¡ç†

### 1. æœåŠ¡å¯åŠ¨å’Œç®¡ç†

```bash
# ä¸€é”®å¯åŠ¨æ‰€æœ‰æœåŠ¡
./start_all.sh

# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡çŠ¶æ€
./start_all.sh --status

# åœæ­¢æ‰€æœ‰æœåŠ¡
./start_all.sh --stop

# é‡å¯æ‰€æœ‰æœåŠ¡
./start_all.sh --restart

# åˆ†åˆ«å¯åŠ¨å„ä¸ªæœåŠ¡
./start_api.sh          # å¯åŠ¨APIæœåŠ¡å™¨
./start_cli.sh --daemon # å¯åŠ¨CLIè°ƒåº¦å™¨ï¼ˆåå°ï¼‰
./start_frontend.sh     # å¯åŠ¨å‰ç«¯å¼€å‘æœåŠ¡å™¨
```

### 2. æœåŠ¡è®¿é—®åœ°å€

```bash
# å‰ç«¯ç•Œé¢
open http://localhost:3000

# APIæ¥å£
curl http://localhost:5001/api/status

# APIæ–‡æ¡£
open http://localhost:5001/api/status
```

## APIæ¥å£ä½¿ç”¨ç¤ºä¾‹

### 1. æ•°æ®æºç®¡ç†API

```bash
# è·å–æ•°æ®æºåˆ—è¡¨
curl -X GET http://localhost:5001/api/data-sources

# åˆ›å»ºæ•°æ®æº
curl -X POST http://localhost:5001/api/data-sources \
  -H "Content-Type: application/json" \
  -d '{
    "name": "test_mysql",
    "type": "mysql",
    "host": "localhost",
    "port": 3306,
    "database": "testdb",
    "username": "user",
    "password": "password",
    "charset": "utf8mb4",
    "description": "æµ‹è¯•æ•°æ®æº"
  }'

# è·å–æ•°æ®æºè¯¦æƒ…
curl -X GET http://localhost:5001/api/data-sources/1

# æµ‹è¯•æ•°æ®æºè¿æ¥
curl -X POST http://localhost:5001/api/data-sources/1/test

# åˆ‡æ¢æ•°æ®æºçŠ¶æ€
curl -X POST http://localhost:5001/api/data-sources/1/toggle

# æ›´æ–°æ•°æ®æº
curl -X PUT http://localhost:5001/api/data-sources/1 \
  -H "Content-Type: application/json" \
  -d '{
    "description": "æ›´æ–°åçš„æè¿°",
    "host": "new-host.example.com"
  }'

# åˆ é™¤æ•°æ®æº
curl -X DELETE http://localhost:5001/api/data-sources/1
```

### 2. ä»»åŠ¡ç®¡ç†API

```bash
# è·å–ä»»åŠ¡åˆ—è¡¨
curl -X GET http://localhost:5001/api/tasks

# æŒ‰çŠ¶æ€è¿‡æ»¤ä»»åŠ¡
curl -X GET "http://localhost:5001/api/tasks?status=active&page=1&per_page=10"

# åˆ›å»ºä»»åŠ¡
curl -X POST http://localhost:5001/api/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "name": "æ—¥é”€å”®æŠ¥è¡¨",
    "description": "æ¯æ—¥é”€å”®æ•°æ®ç»Ÿè®¡æŠ¥è¡¨",
    "data_source_id": 1,
    "sql_content": "SELECT DATE(order_date) as é”€å”®æ—¥æœŸ, COUNT(*) as è®¢å•æ•°é‡, SUM(amount) as é”€å”®é‡‘é¢ FROM orders WHERE DATE(order_date) = CURDATE() - INTERVAL 1 DAY GROUP BY DATE(order_date)",
    "export_methods": "email,dingtalk",
    "export_filename": "daily_sales_report_{date}",
    "cron_expression": "0 9 * * *",
    "created_by": "admin"
  }'

# è·å–ä»»åŠ¡è¯¦æƒ…
curl -X GET http://localhost:5001/api/tasks/1

# æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡
curl -X POST http://localhost:5001/api/tasks/1/execute

# æµ‹è¯•ä»»åŠ¡
curl -X POST http://localhost:5001/api/tasks/1/test

# æ›´æ–°ä»»åŠ¡
curl -X PUT http://localhost:5001/api/tasks/1 \
  -H "Content-Type: application/json" \
  -d '{
    "name": "æ›´æ–°åçš„ä»»åŠ¡åç§°",
    "description": "æ›´æ–°åçš„æè¿°"
  }'

# åˆ é™¤ä»»åŠ¡
curl -X DELETE http://localhost:5001/api/tasks/1
```

### 3. æ‰§è¡Œæ—¥å¿—API

```bash
# è·å–æ‰§è¡Œæ—¥å¿—
curl -X GET http://localhost:5001/api/logs

# è·å–ç‰¹å®šä»»åŠ¡çš„æ—¥å¿—
curl -X GET "http://localhost:5001/api/logs?task_id=1&page=1&per_page=20"

# è·å–ç³»ç»ŸçŠ¶æ€
curl -X GET http://localhost:5001/api/status
```

## CLIç®¡ç†å·¥å…·ä½¿ç”¨ç¤ºä¾‹

### 1. æ•°æ®æºç®¡ç†

```bash
# åˆ—å‡ºæ‰€æœ‰æ•°æ®æº
python cli/manage.py datasource list

# è·å–æ•°æ®æºè¯¦æƒ…
python cli/manage.py datasource get 1

# åˆ›å»ºæ•°æ®æº
python cli/manage.py datasource create test_mysql mysql localhost 3306 testdb user password --charset utf8mb4 --description "æµ‹è¯•æ•°æ®æº"

# æµ‹è¯•æ•°æ®æºè¿æ¥
python cli/manage.py datasource test 1

# åˆ‡æ¢æ•°æ®æºçŠ¶æ€
python cli/manage.py datasource toggle 1

# åˆ é™¤æ•°æ®æº
python cli/manage.py datasource delete 1 --yes
```

### 2. ä»»åŠ¡ç®¡ç†

```bash
# åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡
python cli/manage.py task list

# æŒ‰çŠ¶æ€è¿‡æ»¤ä»»åŠ¡
python cli/manage.py task list --status active --page 1 --per-page 10

# è·å–ä»»åŠ¡è¯¦æƒ…
python cli/manage.py task get 1

# æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡
python cli/manage.py task execute 1

# æµ‹è¯•ä»»åŠ¡
python cli/manage.py task test 1
```

### 3. ç³»ç»Ÿç®¡ç†

```bash
# è·å–ç³»ç»ŸçŠ¶æ€
python cli/manage.py system status

# æ¸…ç†æ—§æ•°æ®
python cli/manage.py system cleanup --days 30
```

### 4. è°ƒåº¦å™¨ç®¡ç†

```bash
# å¯åŠ¨è°ƒåº¦å™¨ï¼ˆå‰å°ï¼‰
./start_cli.sh

# å¯åŠ¨è°ƒåº¦å™¨ï¼ˆåå°ï¼‰
./start_cli.sh --daemon

# æŸ¥çœ‹è°ƒåº¦å™¨çŠ¶æ€
./start_cli.sh --status

# åœæ­¢è°ƒåº¦å™¨
./start_cli.sh --stop
```

## è‡ªå®šä¹‰è„šæœ¬ç¤ºä¾‹

### 1. é”€å”®æ•°æ®åˆ†æè„šæœ¬

```python
# core/scripts/sales_analysis.py

import pandas as pd
from datetime import datetime, timedelta

def daily_sales_analysis(context):
    """
    æ—¥é”€å”®æ•°æ®åˆ†æ
    """
    task = context['task']
    connection_manager = context['connection_manager']
    logger = context['logger']
    
    logger.info("å¼€å§‹æ‰§è¡Œæ—¥é”€å”®æ•°æ®åˆ†æ")
    
    # è·å–æ˜¨å¤©çš„æ—¥æœŸ
    yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    
    # åŸºç¡€é”€å”®æ•°æ®
    sales_sql = f"""
    SELECT 
        product_category,
        product_name,
        SUM(quantity) as total_quantity,
        SUM(amount) as total_amount,
        COUNT(DISTINCT customer_id) as unique_customers,
        AVG(amount) as avg_order_value
    FROM orders o
    JOIN products p ON o.product_id = p.id
    WHERE DATE(o.order_date) = '{yesterday}'
    GROUP BY product_category, product_name
    ORDER BY total_amount DESC
    """
    
    sales_df = connection_manager.execute_query(task.data_source.name, sales_sql)
    
    # æ•°æ®å¤„ç†å’Œåˆ†æ
    # 1. æ·»åŠ å æ¯”è®¡ç®—
    total_sales = sales_df['total_amount'].sum()
    sales_df['sales_percentage'] = (sales_df['total_amount'] / total_sales * 100).round(2)
    
    # 2. æ·»åŠ æ’å
    sales_df['rank'] = sales_df['total_amount'].rank(method='dense', ascending=False).astype(int)
    
    # 3. åˆ†ç±»æ±‡æ€»
    category_summary = sales_df.groupby('product_category').agg({
        'total_quantity': 'sum',
        'total_amount': 'sum',
        'unique_customers': 'sum'
    }).reset_index()
    
    # 4. åˆ›å»ºå¤šå·¥ä½œè¡¨ç»“æœ
    results = {
        'äº§å“é”€å”®æ˜ç»†': sales_df,
        'åˆ†ç±»æ±‡æ€»': category_summary
    }
    
    # 5. æ·»åŠ æ±‡æ€»ä¿¡æ¯
    summary_data = {
        'metric': ['æ€»é”€å”®é¢', 'æ€»è®¢å•æ•°', 'å¹³å‡è®¢å•é‡‘é¢', 'æœ€é«˜å•å“é”€å”®é¢', 'é”€å”®åˆ†ç±»æ•°'],
        'value': [
            f"Â¥{total_sales:,.2f}",
            f"{sales_df['total_quantity'].sum():,}",
            f"Â¥{sales_df['avg_order_value'].mean():.2f}",
            f"Â¥{sales_df['total_amount'].max():,.2f}",
            len(sales_df['product_category'].unique())
        ]
    }
    results['æ±‡æ€»ä¿¡æ¯'] = pd.DataFrame(summary_data)
    
    logger.info(f"é”€å”®æ•°æ®åˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(sales_df)} ä¸ªäº§å“")
    return results
```

### 2. ä½¿ç”¨æ–°æ¶æ„åˆ›å»ºä»»åŠ¡

```python
# é€šè¿‡APIåˆ›å»ºè„šæœ¬ä»»åŠ¡
import requests

api_url = "http://localhost:5001/api/tasks"
task_data = {
    "name": "æ—¥é”€å”®æ•°æ®åˆ†æ",
    "description": "ä½¿ç”¨è‡ªå®šä¹‰è„šæœ¬è¿›è¡Œé”€å”®æ•°æ®åˆ†æ",
    "data_source_id": 1,
    "script_content": "from core.scripts.sales_analysis import daily_sales_analysis\nreturn daily_sales_analysis(context)",
    "export_methods": "email,dingtalk",
    "export_filename": "sales_analysis_{date}",
    "cron_expression": "0 9 * * *",
    "created_by": "admin"
}

response = requests.post(api_url, json=task_data)
print(f"ä»»åŠ¡åˆ›å»ºç»“æœ: {response.json()}")
```

## å‰ç«¯ç•Œé¢ä½¿ç”¨ç¤ºä¾‹

### 1. å¯åŠ¨å‰ç«¯å¼€å‘æœåŠ¡å™¨

```bash
# å¼€å‘æ¨¡å¼
./start_frontend.sh dev

# æ„å»ºç”Ÿäº§ç‰ˆæœ¬
./start_frontend.sh build

# é¢„è§ˆç”Ÿäº§ç‰ˆæœ¬
./start_frontend.sh preview
```

### 2. å‰ç«¯åŠŸèƒ½

è®¿é—® http://localhost:3000 åï¼Œæ‚¨å¯ä»¥ï¼š

- **æ•°æ®æºç®¡ç†**: æ·»åŠ ã€ç¼–è¾‘ã€åˆ é™¤æ•°æ®æº
- **ä»»åŠ¡ç®¡ç†**: åˆ›å»ºã€é…ç½®ã€æ‰§è¡Œä»»åŠ¡
- **æ‰§è¡Œæ—¥å¿—**: æŸ¥çœ‹ä»»åŠ¡æ‰§è¡Œå†å²å’Œç»“æœ
- **ç³»ç»Ÿç›‘æ§**: å®æ—¶æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
- **æ–‡ä»¶ä¸‹è½½**: ä¸‹è½½ç”Ÿæˆçš„æŠ¥è¡¨æ–‡ä»¶

## é€šçŸ¥æ¨¡æ¿ç¤ºä¾‹

### 1. é’‰é’‰æ¶ˆæ¯æ¨¡æ¿

```text
ğŸ“Š {task_name} æ‰§è¡Œå®Œæˆ

â° æ‰§è¡Œæ—¶é—´: {execution_time}
ğŸ“ˆ æ•°æ®è¡Œæ•°: {rows_count:,} è¡Œ
ğŸ’¾ æ–‡ä»¶å¤§å°: {file_size}
âš¡ æ‰§è¡Œè€—æ—¶: {duration}

ğŸ“ æ–‡ä»¶å·²ç”Ÿæˆ: {filename}

âœ… ä»»åŠ¡æ‰§è¡ŒæˆåŠŸï¼Œè¯·æŸ¥æ”¶æ•°æ®æŠ¥å‘Šï¼
```

### 2. é‚®ä»¶æ¨¡æ¿

**ä¸»é¢˜æ¨¡æ¿:**
```text
âœ… æ•°æ®æŠ¥å‘Šå·²ç”Ÿæˆ - {task_name} ({date})
```

**æ­£æ–‡æ¨¡æ¿:**
```text
å°Šæ•¬çš„ç”¨æˆ·ï¼Œ

æ‚¨è®¢é˜…çš„æ•°æ®æŠ¥å‘Šå·²æˆåŠŸç”Ÿæˆï¼

ğŸ“‹ æŠ¥å‘Šä¿¡æ¯:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æŠ¥å‘Šåç§°: {task_name}
ç”Ÿæˆæ—¶é—´: {execution_time}
æ•°æ®è¡Œæ•°: {rows_count:,} è¡Œ
æ–‡ä»¶å¤§å°: {file_size}
å¤„ç†è€—æ—¶: {duration}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ æŠ¥å‘Šæ–‡ä»¶å·²ä½œä¸ºé™„ä»¶å‘é€ï¼Œè¯·æŸ¥æ”¶ã€‚

å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·è”ç³»ç³»ç»Ÿç®¡ç†å‘˜ã€‚

æ­¤é‚®ä»¶ç”±æ•°æ®å¯¼å‡ºç³»ç»Ÿè‡ªåŠ¨å‘é€ï¼Œè¯·å‹¿å›å¤ã€‚

å‘é€æ—¶é—´: {current_time}
```

## å®šæ—¶ä»»åŠ¡é…ç½®ç¤ºä¾‹

### 1. å¸¸ç”¨Cronè¡¨è¾¾å¼

```bash
# æ¯å¤©ä¸Šåˆ9ç‚¹
0 9 * * *

# æ¯å‘¨ä¸€ä¸Šåˆ8ç‚¹
0 8 * * 1

# æ¯æœˆ1å·ä¸Šåˆ10ç‚¹
0 10 1 * *

# æ¯å°æ—¶æ‰§è¡Œ
0 * * * *

# æ¯30åˆ†é’Ÿæ‰§è¡Œ
*/30 * * * *

# å·¥ä½œæ—¥ä¸Šåˆ9ç‚¹
0 9 * * 1-5

# æ¯å­£åº¦ç¬¬ä¸€å¤©
0 9 1 1,4,7,10 *
```

### 2. é€šè¿‡APIé…ç½®å®šæ—¶ä»»åŠ¡

```bash
# åˆ›å»ºæ—¥æŠ¥ä»»åŠ¡
curl -X POST http://localhost:5001/api/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "name": "æ—¥é”€å”®æŠ¥è¡¨",
    "description": "æ¯æ—¥é”€å”®æ•°æ®ç»Ÿè®¡",
    "data_source_id": 1,
    "sql_content": "SELECT DATE(order_date) as é”€å”®æ—¥æœŸ, COUNT(*) as è®¢å•æ•°é‡, SUM(amount) as é”€å”®é‡‘é¢ FROM orders WHERE DATE(order_date) = CURDATE() - INTERVAL 1 DAY GROUP BY DATE(order_date)",
    "export_methods": "email,dingtalk",
    "export_filename": "daily_sales_{date}",
    "cron_expression": "0 9 * * *",
    "status": "active"
  }'

# åˆ›å»ºå‘¨æŠ¥ä»»åŠ¡
curl -X POST http://localhost:5001/api/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "name": "å‘¨é”€å”®æ±‡æ€»",
    "description": "æ¯å‘¨é”€å”®æ•°æ®æ±‡æ€»",
    "data_source_id": 1,
    "sql_content": "SELECT YEARWEEK(order_date) as å‘¨æ¬¡, COUNT(*) as è®¢å•æ•°é‡, SUM(amount) as é”€å”®é‡‘é¢ FROM orders WHERE YEARWEEK(order_date) = YEARWEEK(CURDATE()) - 1 GROUP BY YEARWEEK(order_date)",
    "export_methods": "email",
    "export_filename": "weekly_sales_{year}_W{week}",
    "cron_expression": "0 10 * * 1",
    "status": "active"
  }'
```

## ç›‘æ§å’Œç»´æŠ¤

### 1. æŸ¥çœ‹æœåŠ¡çŠ¶æ€

```bash
# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡çŠ¶æ€
./start_all.sh --status

# æŸ¥çœ‹APIæœåŠ¡å™¨çŠ¶æ€
curl http://localhost:5001/api/status

# æŸ¥çœ‹è°ƒåº¦å™¨çŠ¶æ€
./start_cli.sh --status

# æŸ¥çœ‹ç³»ç»Ÿè¯¦ç»†çŠ¶æ€
python cli/manage.py system status
```

### 2. æŸ¥çœ‹æ—¥å¿—

```bash
# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—
tail -f logs/*.log

# æŸ¥çœ‹APIæœåŠ¡å™¨æ—¥å¿—
tail -f logs/api_server.log

# æŸ¥çœ‹CLIè°ƒåº¦å™¨æ—¥å¿—
tail -f logs/cli_scheduler.log

# æŸ¥çœ‹å‰ç«¯å¼€å‘æœåŠ¡å™¨æ—¥å¿—
tail -f logs/frontend_dev.log
```

### 3. æ‰‹åŠ¨æ‰§è¡Œå’Œæµ‹è¯•

```bash
# é€šè¿‡CLIæ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡
python cli/manage.py task execute 1

# é€šè¿‡APIæ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡
curl -X POST http://localhost:5001/api/tasks/1/execute

# æµ‹è¯•ä»»åŠ¡é…ç½®
python cli/manage.py task test 1

# æµ‹è¯•æ•°æ®æºè¿æ¥
python cli/manage.py datasource test 1
```

## å¼€å‘å’Œè°ƒè¯•

### 1. å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# å®‰è£…Pythonä¾èµ–
pip install -r requirements.txt

# å®‰è£…å‰ç«¯ä¾èµ–
cd frontend && npm install

# å¯åŠ¨å¼€å‘ç¯å¢ƒ
./start_all.sh
```

### 2. APIå¼€å‘

```python
# åœ¨ api/routes/ ä¸­æ·»åŠ æ–°çš„è·¯ç”±
from flask import Blueprint, jsonify, request
from core.services.data_export_service import DataExportService

custom_bp = Blueprint('custom', __name__)
data_export_service = DataExportService()

@custom_bp.route('/api/custom/endpoint', methods=['GET'])
def custom_endpoint():
    try:
        # è‡ªå®šä¹‰ä¸šåŠ¡é€»è¾‘
        result = data_export_service.custom_method()
        return jsonify({
            'success': True,
            'data': result
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# åœ¨ api/app.py ä¸­æ³¨å†Œè·¯ç”±
app.register_blueprint(custom_bp)
```

### 3. å‰ç«¯å¼€å‘

```typescript
// åœ¨ frontend/src/utils/ ä¸­æ·»åŠ APIè°ƒç”¨
import axios from 'axios'

const API_BASE_URL = 'http://localhost:5001'

export const apiClient = axios.create({
  baseURL: API_BASE_URL,
  timeout: 10000,
  headers: {
    'Content-Type': 'application/json'
  }
})

// æ•°æ®æºAPI
export const dataSourceApi = {
  list: () => apiClient.get('/api/data-sources'),
  create: (data: any) => apiClient.post('/api/data-sources', data),
  get: (id: number) => apiClient.get(`/api/data-sources/${id}`),
  update: (id: number, data: any) => apiClient.put(`/api/data-sources/${id}`, data),
  delete: (id: number) => apiClient.delete(`/api/data-sources/${id}`),
  test: (id: number) => apiClient.post(`/api/data-sources/${id}/test`)
}

// ä»»åŠ¡API
export const taskApi = {
  list: (params?: any) => apiClient.get('/api/tasks', { params }),
  create: (data: any) => apiClient.post('/api/tasks', data),
  get: (id: number) => apiClient.get(`/api/tasks/${id}`),
  update: (id: number, data: any) => apiClient.put(`/api/tasks/${id}`, data),
  delete: (id: number) => apiClient.delete(`/api/tasks/${id}`),
  execute: (id: number) => apiClient.post(`/api/tasks/${id}/execute`),
  test: (id: number) => apiClient.post(`/api/tasks/${id}/test`)
}
```

## æ•…éšœæ’é™¤

### 1. å¸¸è§é—®é¢˜è§£å†³

```bash
# é—®é¢˜ï¼šæœåŠ¡å¯åŠ¨å¤±è´¥
# è§£å†³ï¼šæ£€æŸ¥ç«¯å£å ç”¨
lsof -i :3000  # å‰ç«¯ç«¯å£
lsof -i :5001  # APIç«¯å£

# é—®é¢˜ï¼šAPIè¿æ¥å¤±è´¥
# è§£å†³ï¼šæ£€æŸ¥APIæœåŠ¡çŠ¶æ€
curl http://localhost:5001/api/status

# é—®é¢˜ï¼šæ•°æ®åº“è¿æ¥å¤±è´¥
# è§£å†³ï¼šæµ‹è¯•æ•°æ®åº“è¿æ¥
python -c "
from core.database.manager import DatabaseManager
from core.utils.config_manager import ConfigManager
config = ConfigManager().config
db = DatabaseManager(config)
print('è¿æ¥æˆåŠŸ' if db.test_connection() else 'è¿æ¥å¤±è´¥')
"

# é—®é¢˜ï¼šä»»åŠ¡æ‰§è¡Œå¤±è´¥
# è§£å†³ï¼šæŸ¥çœ‹æ‰§è¡Œæ—¥å¿—
python cli/manage.py task execute 1
tail -f logs/cli_scheduler.log
```

### 2. æ€§èƒ½ä¼˜åŒ–

```yaml
# config.yaml æ€§èƒ½ä¼˜åŒ–é…ç½®
scheduler:
  timezone: "Asia/Shanghai"
  max_workers: 3  # æ ¹æ®æœåŠ¡å™¨æ€§èƒ½è°ƒæ•´

# æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–
data_sources:
  mysql_prod:
    # ... å…¶ä»–é…ç½®
    connection_params: |
      {
        "pool_size": 5,
        "max_overflow": 10,
        "pool_timeout": 30,
        "pool_recycle": 3600
      }
```

## éƒ¨ç½²æŒ‡å—

### 1. å¼€å‘ç¯å¢ƒéƒ¨ç½²

```bash
# ä¸€é”®å¯åŠ¨å¼€å‘ç¯å¢ƒ
./start_all.sh

# è®¿é—®åœ°å€
echo "å‰ç«¯ç•Œé¢: http://localhost:3000"
echo "APIæ¥å£: http://localhost:5001"
```

### 2. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

```bash
# å‰ç«¯æ„å»º
./start_frontend.sh build

# APIæœåŠ¡å™¨éƒ¨ç½²
pip install gunicorn
gunicorn -w 4 -b 0.0.0.0:5001 api.app:app

# CLIè°ƒåº¦å™¨éƒ¨ç½²
./start_cli.sh --daemon

# ä½¿ç”¨systemdç®¡ç†æœåŠ¡
sudo systemctl enable dataapp-api
sudo systemctl enable dataapp-cli
sudo systemctl start dataapp-api
sudo systemctl start dataapp-cli
```

### 3. Dockeréƒ¨ç½²ï¼ˆå¯é€‰ï¼‰

```dockerfile
# Dockerfile
FROM python:3.8-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 5001
CMD ["python", "api/app.py"]
```

```bash
# æ„å»ºå’Œè¿è¡Œ
docker build -t dataapp .
docker run -d -p 5001:5001 --name dataapp-api dataapp
```

## æœ€ä½³å®è·µ

### 1. ä»»åŠ¡è®¾è®¡åŸåˆ™

- **å•ä¸€èŒè´£**: æ¯ä¸ªä»»åŠ¡åªè´Ÿè´£ä¸€ä¸ªç‰¹å®šçš„æ•°æ®å¯¼å‡ºéœ€æ±‚
- **å¹‚ç­‰æ€§**: é‡å¤æ‰§è¡ŒåŒä¸€ä»»åŠ¡åº”è¯¥äº§ç”Ÿç›¸åŒç»“æœ
- **é”™è¯¯å¤„ç†**: åˆç†å¤„ç†å¼‚å¸¸æƒ…å†µï¼Œæä¾›æœ‰æ„ä¹‰çš„é”™è¯¯ä¿¡æ¯
- **æ€§èƒ½è€ƒè™‘**: é¿å…å¤§æ•°æ®é‡æŸ¥è¯¢ï¼Œä½¿ç”¨åˆ†é¡µæˆ–é™åˆ¶æ¡ä»¶

### 2. APIè®¾è®¡åŸåˆ™

- **RESTful**: éµå¾ªREST APIè®¾è®¡è§„èŒƒ
- **ç»Ÿä¸€å“åº”**: ä½¿ç”¨ç»Ÿä¸€çš„å“åº”æ ¼å¼
- **é”™è¯¯å¤„ç†**: æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’ŒçŠ¶æ€ç 
- **ç‰ˆæœ¬æ§åˆ¶**: ä¸ºAPIæ·»åŠ ç‰ˆæœ¬æ§åˆ¶

### 3. å®‰å…¨å»ºè®®

- **å¯†ç ç®¡ç†**: ä½¿ç”¨å¼ºå¯†ç ï¼Œå®šæœŸæ›´æ¢
- **æƒé™æ§åˆ¶**: ä½¿ç”¨åªè¯»è´¦æˆ·è¿›è¡Œæ•°æ®æŸ¥è¯¢
- **ç½‘ç»œå®‰å…¨**: é™åˆ¶æ•°æ®åº“è®¿é—®IPèŒƒå›´
- **æ—¥å¿—å®¡è®¡**: å®šæœŸæ£€æŸ¥æ‰§è¡Œæ—¥å¿—ï¼Œå‘ç°å¼‚å¸¸è¡Œä¸º

### 4. è¿ç»´å»ºè®®

- **å®šæœŸå¤‡ä»½**: å¤‡ä»½ç³»ç»Ÿæ•°æ®åº“å’Œé…ç½®æ–‡ä»¶
- **ç›‘æ§å‘Šè­¦**: è®¾ç½®ä»»åŠ¡å¤±è´¥å‘Šè­¦æœºåˆ¶
- **èµ„æºç›‘æ§**: ç›‘æ§æœåŠ¡å™¨CPUã€å†…å­˜ã€ç£ç›˜ä½¿ç”¨æƒ…å†µ
- **æ—¥å¿—è½®è½¬**: å®šæœŸæ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶

é€šè¿‡ä»¥ä¸Šç¤ºä¾‹ï¼Œæ‚¨åº”è¯¥èƒ½å¤Ÿå¿«é€Ÿä¸Šæ‰‹å¹¶æœ‰æ•ˆä½¿ç”¨æ–°æ¶æ„çš„æ•°æ®å¯¼å‡ºç³»ç»Ÿã€‚å¦‚æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·å‚è€ƒ README_NEW_ARCHITECTURE.md æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚